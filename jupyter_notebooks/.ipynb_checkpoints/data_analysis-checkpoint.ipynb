{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import networkx as nx\n",
    "# from networkx.readwrite import json_graph\n",
    "\n",
    "import pickle as pkl\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "def load_reddit_data():\n",
    "    \n",
    "    G = nx.read_edgelist(\"../data/reddit/reddit_G.edg\", delimiter=\" \", data=True)\n",
    "    nx.set_edge_attributes(G=G, name=\"weight\", values=1)\n",
    "\n",
    "    feats = np.load(\"../data/reddit/reddit-feats.npy\")\n",
    "    id_map = json.load(open(\"../data/reddit/reddit-id_map.json\"))\n",
    "    conversion = lambda n : n\n",
    "    id_map = {conversion(k):int(v) for k,v in id_map.items()}\n",
    "    \n",
    "    G = nx.relabel_nodes(G, id_map, )\n",
    "\n",
    "    with open(\"../data/reddit/train_nodes\", \"rb\") as f:\n",
    "        train_nodes = pkl.load(f)\n",
    "    with open(\"../data/reddit/val_nodes\", \"rb\") as f:\n",
    "        val_nodes = pkl.load(f)\n",
    "    with open(\"../data/reddit/test_nodes\", \"rb\") as f:\n",
    "        test_nodes = pkl.load(f)\n",
    "        \n",
    "    train_idx = [id_map[n] for n in train_nodes]\n",
    "    val_idx = [id_map[n] for n in val_nodes]\n",
    "    test_idx = [id_map[n] for n in test_nodes]\n",
    "    \n",
    "    # normalize by training data\n",
    "    train_feats = feats[train_idx]\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_feats)\n",
    "    feats = scaler.transform(feats)\n",
    "    \n",
    "    X = feats\n",
    "    \n",
    "    class_map = json.load(open(\"../data/reddit/reddit-class_map.json\"))\n",
    "    if isinstance(list(class_map.values())[0], list):\n",
    "        lab_conversion = lambda n : n\n",
    "    else:\n",
    "        lab_conversion = lambda n : int(n)\n",
    "    class_map = {conversion(k):lab_conversion(v) for k,v in class_map.items()}\n",
    "    \n",
    "    num_classes = max(class_map.values())\n",
    "    class_map = {id_map[k]: v for k, v in class_map.items()}\n",
    "    \n",
    "    Y = csr_matrix(([1] * len(class_map), (class_map.keys(), class_map.values())), shape=(len(class_map), num_classes))\n",
    "#     Y = np.zeros((len(class_map), num_classes))\n",
    "#     for n, c in class_map.items():\n",
    "#         Y[n, c] = 1\n",
    "        \n",
    "    train_G = G.subgraph(train_idx)\n",
    "    val_G = G.subgraph(train_idx + val_idx)\n",
    "    test_G = G\n",
    "\n",
    "    return train_G, val_G, test_G, X, Y, train_idx, val_idx, test_idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10x10 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 3 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_idx = [1,2,3]\n",
    "col_idx = [4,5,6]\n",
    "\n",
    "data = [1]*3\n",
    "\n",
    "csr_matrix((data, (row_idx, col_idx)), shape=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_G, val_G, test_G, X, Y, train_idx, val_idx, test_idx = load_reddit_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
